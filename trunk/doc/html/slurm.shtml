<!--#include virtual="header.txt"-->

<h1>SLURM: A Highly Scalable Resource Manager</h1>
<p>SLURM is an open-source resource manager designed for Linux clusters of all 
sizes. It provides three key functions. First it allocates exclusive and/or non-exclusive 
access to resources (computer nodes) to users for some duration of time so they 
can perform work. Second, it provides a framework for starting, executing, and 
monitoring work (typically a parallel job) on a set of allocated nodes. Finally, 
it arbitrates contention for resources by managing a queue of pending work. </p>

<p>SLURM is not a sophisticated batch system, but it does provide an Applications 
Programming Interface (API) for integration with external schedulers such as 
<a href="http://www.clusterresources.com/pages/products/maui-cluster-scheduler.php">
The Maui Scheduler</a> and 
<a href="http://www.clusterresources.com/pages/products/moab-cluster-suite.php">
Moab Cluster Suite</a>.
While other resource managers do exist, SLURM is unique in several respects: 
<ul>
<li>Its source code is freely available under the 
<a href="http://www.gnu.org/licenses/gpl.html">GNU General Public License</a>.</li>
<li>It is designed to operate in a heterogeneous cluster with up to 65,536 nodes.</li>
<li>It is portable; written in C with a GNU autoconf configuration engine. While 
initially written for Linux, other UNIX-like operating systems should be easy 
porting targets. A plugin mechanism exists to support various interconnects, authentication 
mechanisms, schedulers, etc.</li>
<li>SLURM is highly tolerant of system failures, including failure of the node 
executing its control functions.</li>
<li>It is simple enough for the motivated end user to understand its source and 
add functionality.</li>
</ul></p>

<p>SLURM provides resource management on about 1000 computers worldwide,
including many of the most powerful computers in the world:
<ul>
<li><a href="https://asc.llnl.gov/computing_resources/bluegenel/">BlueGene/L</a> 
at LLNL with 106,496 dual-core processors</li>
<li><a href="http://c-r-labs.com/">EKA</a> at Computational Research Laboratories, 
India with 14,240 Xeon processoers and Infiniband interconnect</li>
<li><a href="https://asc.llnl.gov/computing_resources/purple/">ASC Purple</a>
an IBM SP/AIX cluster at LLNL with 12,208 Power5 processors and a Federation switch</li>
<li><a href="http://www.bsc.es/plantillaA.php?cat_id=5">MareNostrum</a>
a Linux cluster at Barcelona Supercomputer Center
with 10,240 PowerPC processors and a Myrinet switch</li>
</ul>
<p>SLURM is actively being developed, distributed and supported by 
<a href="https://www.llnl.gov">Lawrence Livermore National Laboratory</a>,
<a href="http://www.hp.com">Hewlett-Packard</a>,
<a href="http://www.bull.com">Bull</a>,
<a href="http://www.clusterresources.com">Cluster Resources</a> and
<a href="http://www.sicortex.com">SiCortex</a>.</p>

<p style="text-align:center;">Last modified 29 November 2007</p>

<!--#include virtual="footer.txt"-->
