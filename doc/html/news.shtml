<!--#include virtual="header.txt"-->

<h1>What's New</h1>

<h2>Index</h2>
<ul>
<li><a href="#13">SLURM Version 1.3, March 2008</a></li>
<li><a href="#20">SLURM Version 2.0, May 2009</a></li>
<li><a href="#21">SLURM Version 2.1 and beyond</a></li>
</ul>

<h2><a name="13">Major Updates in SLURM Version 1.3</a></h2>
<p>SLURM Version 1.3 was released in March 2008.
Major enhancements include:
<ul>
<li>Job accounting and completion data can be stored in a database 
(MySQL, PGSQL or simple text file).</li>
<li>SlurmDBD (Slurm Database Deamon) introduced to provide secure
database support across multiple clusters.</li>
<li>Gang scheduler plugin added (time-slicing of parallel jobs
without an external scheduler).</li>
<li>Cryptography logic moved to a separate plugin with the 
option of using OpenSSL (default) or Munge (GPL).</li>
<li>Improved scheduling of multiple job steps within a job's allocation.</li>
<li>Support for job specification of node features with node counts.</li> 
<li><i>srun</i>'s --alloc, --attach, and --batch options removed (use 
<i>salloc</i>, <i>sattach</i> or <i>sbatch</i> commands instead).</li>
<li><i>srun --pty</i> option added to support remote pseudo terminal for 
spawned tasks.</li>
<li>Support added for a much richer job dependency specification
including testing of exit codes and multiple dependencies.</li>
<li>Support added for BlueGene/P systems and HTC (High Throughput
Computing) mode.</li>
</ul>

<h2><a name="20">Major Updates in SLURM Version 2.0</a></h2>
<p>SLURM Version 2.0 is scheduled for released in May 2009.
Major enhancements include:
<ul>
<li>Sophisticated <a href="priority_multifactor.html">job prioritization 
plugin</a> is now available. 
Jobs can be prioritized based upon their age, size and/or fair-share resource 
allocation using hierarchical bank accounts.</li>
<li>An assortment of <a href="resource_limits.html">resource limits</a> 
can be imposed upon individual users and/or hierarchical bank accounts 
such as maximum job time limit, maximum job size, and maximum number of 
running jobs.</li>
<li><a href="reservations.html">Advanced reservations</a> can be made to 
insure resources will be available when needed.</li>
<li>Idle nodes can now be completely <a href="power_save.html">powered 
down</a> when idle and automatically restarted when their is work 
available.</li>
<li>Jobs in higher priority partitions (queues) can automatically 
<a href="preempt.html">preempt</a> jobs in lower priority queues. 
The preempted jobs will automatically resume execution upon completion 
of the higher priority job.</li>
<li>Specific cores are allocated to jobs and jobs steps in order to effective 
preempt or gang schedule jobs.</li>
<li>A new configuration parameter, <i>PrologSlurmctld</i>, can be used to 
support the booting of different operating systems for each job.</li>
<li>Added switch topology configuration options to optimize job resource 
allocation with respect to communication performance.</li>
<li>Automatic <a href="checkpoint_blcr.html">Checkpoint/Restart using BRCR</a> 
is now available.</li>
</ul>

<h2><a name="21">Major Updates in SLURM Version 2.1 and beyond</a></h2>
<p> Detailed plans for release dates and contents of future SLURM releases have 
not been finalized. Anyone desiring to perform SLURM development should notify
<a href="mailto:slurm-dev@lists.llnl.gov">slurm-dev@lists.llnl.gov</a>
to coordinate activities. Future development plans includes:
<ul>
<li>Optimized resource allocation based upon network topology (e.g.
hierarchical switches).</li>
<li>Modify more SLURM commands to operate between clusters.</li>
<li>Support for BlueGene/Q systems.</li>
<li>Permit resource allocations (jobs) to change size.</li>
<li>Add Kerberos credential support including credential forwarding 
and refresh.</li>
</ul>

<p style="text-align:center;">Last modified 5 March 2009</p>

<!--#include virtual="footer.txt"-->
