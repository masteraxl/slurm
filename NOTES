Possible issues:
* Require basic documentation for most of these functions (they are
  not defined within "LoadLeveler for AIX 5L V3.2, Using and Administering").
* Slurm job_id is of type uint64_t, not "host.#". What is passed to 
  ll_set_request and how is it gathered? We just want a number passed.
* Need to establish guidelines for ll_version().
* Need to establish parallel ll_spawn().
* Need to add adapter info: protocol, usage (IP or US), address, 
  window number, adapter device, usage instance (see _get_data_adapter).
* Need task info by node (task count, iterate through tasks, see _get_data_task).
* Need task instance info (see _get_data_task_inst).
* Need to resolve how to handle process tracking (who does what).
* Need to support JCL environment parameters.
* Only support a single SLURM job step per poe job.
* Remove slurm/*.h and llapi.h from code base when everything is installed.
* SLURM's concept of a job step is quite different from LoadLeveler's
  This causes some difficulties in ll_get_data as well as general job
  launch mechanisms.
* Only one job step per job is currently permitted. The mapping of parameters 
  between jobs and steps varies greatly between SLURM and LoadLeveler. We only 
  expect one step per job anyway (at least for the LCRM/DPCS batch jobs).
* slurmd does not terminate on "scontrol shutdown"
* User must specify partition name (-rmpool <name>) to insure that a 
  hostlist file does not attempt to be used later, which can permit an 
  arbitrary task layout on the nodes and is not supported by SLURM.
* Add time parsing to ll_parse_string for WALL_CLOCK_LIMIT
* To build
  cc common.c -lslurm -bM:SRE -e slurm_funcs -o llapi_shr.o -I. -I/usr/lpp/LoadL/full/include
  ln -s /usr/lib/llapi_shr.o /g/g0/jette/slurm_ll_api/llapi_shr.o
  set MP_RMLIB environment variable to point to local llapi_shr.o file and
  invoke local poe: 
    bash
    MP_RMLIB=/g/g0/jette/slurm_ll_api/llapi_shr.o
    ./poe hostname -rmpool debug -resd yes -euilib ip -euidevice en0 -infolevel 7
    ./poe hostname -rmpool debug -resd yes -euilib ip -euidevice en0 -nodes 24 -procs 24 -infolevel 7
* Define data structures for LL_element after understanding how it is used.
* We have a simple pmdv3 test code that just logs what is read from stdin.
  Build it by running "make test", then copy pmdv3test to /etc, then 
  set MP_PMDSUFFIX=test, and run poe as above. Look for the log in 
  "/tmp/mplog.<pid>"

Notes on functions and options to be supported:
ll_deallocate		
ll_query		Get JOBS info, not CLUSTERS or MACHINES
ll_set_request		Set one JOBID only, no other filters or objects
ll_get_objs		Gets info for one JOBID
ll_get_data		Just started, args identified already
ll_free_objs

Not documented (we do have their definitions in llapi.h and brief 
  description from Waiman for some of them, but require more complete 
  documentation including error codes to emulate):
ll_fetch
ll_set_data
ll_init_job
ll_deallocate_job
ll_parse_string
ll_parse_file
ll_parse_verify
ll_request
ll_spawn
ll_event
ll_get_job
ll_close
ll_version
ll_spawn_task
ll_local_ckpt_start
ll_local_ckpt_complete
ll_ckpt_complete

